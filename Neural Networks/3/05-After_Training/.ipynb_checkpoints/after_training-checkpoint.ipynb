{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Training\n",
    "\n",
    "\n",
    "In this activity, you will create a deep learning model from the credit score data, save it, and load it to evaluate its performance on unseen data.\n",
    "\n",
    "1. Split the data into training and test sets using the `train_test_split` method from `sklearn`. Then scale the features data using an instance of the `StandardScaler`.\n",
    "\n",
    "2. Using the training set, construct a shallow neural net model to predict the credit score features (you can use the same model that you constructed in the _Credit Scoring_ Activity).\n",
    "\n",
    "> **Note** When fitting the model, you will not need a `validation-split` parameter because the data was seperated into training and testing datasets.\n",
    "\n",
    "3. Using relative file paths, save the model and its weights.\n",
    "\n",
    "4. Load the model and its weights.\n",
    "\n",
    "5.  Use this loaded model to predict points for the test data and print the mean squared error metric for the predicted points vs. the actual points.\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "This dataset is built around the same dataset used in the previous activity. The dataset contains `68` encoded features (columns from `0` to `67`), with all personal identifying information removed. The last two columns of the dataset (columns `68` and `69`) are preliminary credit score quality indicators that have been manually assigned by staff at the firm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.504263</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>-1.018726</td>\n",
       "      <td>-0.174878</td>\n",
       "      <td>-1.089543</td>\n",
       "      <td>-0.668840</td>\n",
       "      <td>-0.914772</td>\n",
       "      <td>-0.836250</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.495712</td>\n",
       "      <td>-0.465077</td>\n",
       "      <td>-0.157861</td>\n",
       "      <td>-0.157189</td>\n",
       "      <td>0.380951</td>\n",
       "      <td>1.088478</td>\n",
       "      <td>-0.123595</td>\n",
       "      <td>1.391141</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637167</td>\n",
       "      <td>0.147260</td>\n",
       "      <td>0.217914</td>\n",
       "      <td>2.718442</td>\n",
       "      <td>0.972919</td>\n",
       "      <td>2.081069</td>\n",
       "      <td>1.375763</td>\n",
       "      <td>1.063847</td>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178325</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>-0.724247</td>\n",
       "      <td>-1.020687</td>\n",
       "      <td>-0.751380</td>\n",
       "      <td>-0.385005</td>\n",
       "      <td>-0.012326</td>\n",
       "      <td>-0.392197</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.919463</td>\n",
       "      <td>-0.667912</td>\n",
       "      <td>-0.820172</td>\n",
       "      <td>-0.190488</td>\n",
       "      <td>0.306974</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.271838</td>\n",
       "      <td>1.289783</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1  0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2 -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3 -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4  0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "\n",
       "         7         8         9   ...        60        61        62        63  \\\n",
       "0 -1.205671  1.849122 -0.425598  ... -1.504263  0.351267 -1.018726 -0.174878   \n",
       "1 -0.887385  0.432062 -0.093963  ... -0.495712 -0.465077 -0.157861 -0.157189   \n",
       "2 -0.694895 -0.901869 -1.701574  ... -0.637167  0.147260  0.217914  2.718442   \n",
       "3  0.114752  0.692847  0.052377  ... -0.178325 -0.065059 -0.724247 -1.020687   \n",
       "4 -0.401676 -0.872639  1.147483  ... -0.919463 -0.667912 -0.820172 -0.190488   \n",
       "\n",
       "         64        65        66        67     68     69  \n",
       "0 -1.089543 -0.668840 -0.914772 -0.836250 -15.75 -47.95  \n",
       "1  0.380951  1.088478 -0.123595  1.391141  14.91 -23.51  \n",
       "2  0.972919  2.081069  1.375763  1.063847  12.65  -8.00  \n",
       "3 -0.751380 -0.385005 -0.012326 -0.392197   9.03  38.74  \n",
       "4  0.306974  0.119658  0.271838  1.289783  34.03  -6.85  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "data = Path(\"credit_scores.csv\")\n",
    "df = pd.read_csv(data, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.944584</td>\n",
       "      <td>-0.043610</td>\n",
       "      <td>-1.504263</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>-1.018726</td>\n",
       "      <td>-0.174878</td>\n",
       "      <td>-1.089543</td>\n",
       "      <td>-0.668840</td>\n",
       "      <td>-0.914772</td>\n",
       "      <td>-0.836250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082645</td>\n",
       "      <td>-0.947933</td>\n",
       "      <td>-0.495712</td>\n",
       "      <td>-0.465077</td>\n",
       "      <td>-0.157861</td>\n",
       "      <td>-0.157189</td>\n",
       "      <td>0.380951</td>\n",
       "      <td>1.088478</td>\n",
       "      <td>-0.123595</td>\n",
       "      <td>1.391141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.797954</td>\n",
       "      <td>-0.556109</td>\n",
       "      <td>-0.637167</td>\n",
       "      <td>0.147260</td>\n",
       "      <td>0.217914</td>\n",
       "      <td>2.718442</td>\n",
       "      <td>0.972919</td>\n",
       "      <td>2.081069</td>\n",
       "      <td>1.375763</td>\n",
       "      <td>1.063847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.805626</td>\n",
       "      <td>0.166616</td>\n",
       "      <td>-0.178325</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>-0.724247</td>\n",
       "      <td>-1.020687</td>\n",
       "      <td>-0.751380</td>\n",
       "      <td>-0.385005</td>\n",
       "      <td>-0.012326</td>\n",
       "      <td>-0.392197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180181</td>\n",
       "      <td>-0.500785</td>\n",
       "      <td>-0.919463</td>\n",
       "      <td>-0.667912</td>\n",
       "      <td>-0.820172</td>\n",
       "      <td>-0.190488</td>\n",
       "      <td>0.306974</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.271838</td>\n",
       "      <td>1.289783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1  0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2 -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3 -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4  0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "\n",
       "         7         8         9   ...        58        59        60        61  \\\n",
       "0 -1.205671  1.849122 -0.425598  ... -0.944584 -0.043610 -1.504263  0.351267   \n",
       "1 -0.887385  0.432062 -0.093963  ... -0.082645 -0.947933 -0.495712 -0.465077   \n",
       "2 -0.694895 -0.901869 -1.701574  ... -0.797954 -0.556109 -0.637167  0.147260   \n",
       "3  0.114752  0.692847  0.052377  ... -0.805626  0.166616 -0.178325 -0.065059   \n",
       "4 -0.401676 -0.872639  1.147483  ... -0.180181 -0.500785 -0.919463 -0.667912   \n",
       "\n",
       "         62        63        64        65        66        67  \n",
       "0 -1.018726 -0.174878 -1.089543 -0.668840 -0.914772 -0.836250  \n",
       "1 -0.157861 -0.157189  0.380951  1.088478 -0.123595  1.391141  \n",
       "2  0.217914  2.718442  0.972919  2.081069  1.375763  1.063847  \n",
       "3 -0.724247 -1.020687 -0.751380 -0.385005 -0.012326 -0.392197  \n",
       "4 -0.820172 -0.190488  0.306974  0.119658  0.271838  1.289783  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features set 'X', and the target 'y' set\n",
    "\n",
    "# The features dataset consists of columns 0 to 67\n",
    "X = df.iloc[:, 0:68]\n",
    "\n",
    "# The target conststs of columns 68 and 69\n",
    "y = df.iloc[:, 68:70]\n",
    "\n",
    "# View data for the features set\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Split the data into training and test sets using the `train_test_split` method from `sklearn`. Then scale the features data using an instance of the `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into traning and testing sets using the train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data for the features set X_tain and X_test\n",
    "\n",
    "# Fit the training data to a StandardScaler instance\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Scale the training data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# Scale the testing data\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Using the training set, construct a shallow neural net model to predict the credit score data (you can use the same model that you constructed in the _Credit Scoring_ Activity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shallow, 1 hidden layer, neural network\n",
    "\n",
    "# Instantiate an instance of the Sequential model\n",
    "nn = Sequential()\n",
    "\n",
    "# Create 1 hidden layer\n",
    "nn.add(Dense(units=8, input_dim=68, activation='relu'))\n",
    "\n",
    "# Create the output layer\n",
    "nn.add(Dense(units=2, activation='linear'))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and mse.\n",
    "nn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the training data\n",
    "model_1 = nn.fit(X_train_scaled, y_train, epochs=100, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the train function\n",
    "plt.plot(model_1.history[\"loss\"])\n",
    "plt.title(\"loss_function - training\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Using relative file paths, save the model and its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in JSON format\n",
    "nn_json = nn.to_json()\n",
    "\n",
    "# Define a relative path to save the model\n",
    "# The model should be saved with a .json file extension\n",
    "file_path = ('Resources/model.json')\n",
    "\n",
    "# Write the model to the the file \n",
    "with open(file_path, 'w') as json_file:\n",
    "    json_file.write(nn_json)\n",
    "\n",
    "# Define a relative path to save the model weights\n",
    "# The model weights should be saved with a .h5 file extension\n",
    "file_path = ('Resources/model.h5')\n",
    "\n",
    "# Save the weights to the file path\n",
    "nn.save_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load the model and its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model to predict values\n",
    "from tensorflow.keras.models import model_from_json\n",
    "# Identify the relative path of the model's location\n",
    "file_path = ('Resources/model.json')\n",
    "\n",
    "# Read in the model and save it as the variable loaded_model\n",
    "with open(file_path, 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "loaded_model= model_from_json(model_json)\n",
    "\n",
    "# Identify the relative path for the model's weights\n",
    "file_path = ('Resources/model.h5')\n",
    "\n",
    "# Load the model's weights to the variable loaded_model\n",
    "loaded_model.load_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Use this loaded model to predict points for the test data and print the mean squared error metric for the predicted points vs. the actual points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.753185, 27.741785],\n",
       "       [27.000578, 42.344048],\n",
       "       [35.518047, 84.72433 ],\n",
       "       [11.769918, 23.4219  ],\n",
       "       [27.265612, 49.017082]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict values using the testing data\n",
    "y_pred = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "# View the model's predictions\n",
    "y_pred[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350.2193924645023\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Evaluate the model with the MSE metric\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "nteract": {
   "version": "0.28.0"
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
