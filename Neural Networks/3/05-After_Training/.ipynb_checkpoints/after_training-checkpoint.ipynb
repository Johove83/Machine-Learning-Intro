{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Training\n",
    "\n",
    "\n",
    "In this activity, you will create a deep learning model from the credit score data, save it, and load it to evaluate its performance on unseen data.\n",
    "\n",
    "1. Split the data into training and test sets using the `train_test_split` method from `sklearn`. Then scale the features data using an instance of the `StandardScaler`.\n",
    "\n",
    "2. Using the training set, construct a shallow neural net model to predict the credit score features (you can use the same model that you constructed in the _Credit Scoring_ Activity).\n",
    "\n",
    "> **Note** When fitting the model, you will not need a `validation-split` parameter because the data was seperated into training and testing datasets.\n",
    "\n",
    "3. Using relative file paths, save the model and its weights.\n",
    "\n",
    "4. Load the model and its weights.\n",
    "\n",
    "5.  Use this loaded model to predict points for the test data and print the mean squared error metric for the predicted points vs. the actual points.\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "This dataset is built around the same dataset used in the previous activity. The dataset contains `68` encoded features (columns from `0` to `67`), with all personal identifying information removed. The last two columns of the dataset (columns `68` and `69`) are preliminary credit score quality indicators that have been manually assigned by staff at the firm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.504263</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>-1.018726</td>\n",
       "      <td>-0.174878</td>\n",
       "      <td>-1.089543</td>\n",
       "      <td>-0.668840</td>\n",
       "      <td>-0.914772</td>\n",
       "      <td>-0.836250</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.495712</td>\n",
       "      <td>-0.465077</td>\n",
       "      <td>-0.157861</td>\n",
       "      <td>-0.157189</td>\n",
       "      <td>0.380951</td>\n",
       "      <td>1.088478</td>\n",
       "      <td>-0.123595</td>\n",
       "      <td>1.391141</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637167</td>\n",
       "      <td>0.147260</td>\n",
       "      <td>0.217914</td>\n",
       "      <td>2.718442</td>\n",
       "      <td>0.972919</td>\n",
       "      <td>2.081069</td>\n",
       "      <td>1.375763</td>\n",
       "      <td>1.063847</td>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178325</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>-0.724247</td>\n",
       "      <td>-1.020687</td>\n",
       "      <td>-0.751380</td>\n",
       "      <td>-0.385005</td>\n",
       "      <td>-0.012326</td>\n",
       "      <td>-0.392197</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.919463</td>\n",
       "      <td>-0.667912</td>\n",
       "      <td>-0.820172</td>\n",
       "      <td>-0.190488</td>\n",
       "      <td>0.306974</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.271838</td>\n",
       "      <td>1.289783</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1  0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2 -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3 -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4  0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "\n",
       "         7         8         9   ...        60        61        62        63  \\\n",
       "0 -1.205671  1.849122 -0.425598  ... -1.504263  0.351267 -1.018726 -0.174878   \n",
       "1 -0.887385  0.432062 -0.093963  ... -0.495712 -0.465077 -0.157861 -0.157189   \n",
       "2 -0.694895 -0.901869 -1.701574  ... -0.637167  0.147260  0.217914  2.718442   \n",
       "3  0.114752  0.692847  0.052377  ... -0.178325 -0.065059 -0.724247 -1.020687   \n",
       "4 -0.401676 -0.872639  1.147483  ... -0.919463 -0.667912 -0.820172 -0.190488   \n",
       "\n",
       "         64        65        66        67     68     69  \n",
       "0 -1.089543 -0.668840 -0.914772 -0.836250 -15.75 -47.95  \n",
       "1  0.380951  1.088478 -0.123595  1.391141  14.91 -23.51  \n",
       "2  0.972919  2.081069  1.375763  1.063847  12.65  -8.00  \n",
       "3 -0.751380 -0.385005 -0.012326 -0.392197   9.03  38.74  \n",
       "4  0.306974  0.119658  0.271838  1.289783  34.03  -6.85  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "data = Path(\"credit_scores.csv\")\n",
    "df = pd.read_csv(data, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.944584</td>\n",
       "      <td>-0.043610</td>\n",
       "      <td>-1.504263</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>-1.018726</td>\n",
       "      <td>-0.174878</td>\n",
       "      <td>-1.089543</td>\n",
       "      <td>-0.668840</td>\n",
       "      <td>-0.914772</td>\n",
       "      <td>-0.836250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082645</td>\n",
       "      <td>-0.947933</td>\n",
       "      <td>-0.495712</td>\n",
       "      <td>-0.465077</td>\n",
       "      <td>-0.157861</td>\n",
       "      <td>-0.157189</td>\n",
       "      <td>0.380951</td>\n",
       "      <td>1.088478</td>\n",
       "      <td>-0.123595</td>\n",
       "      <td>1.391141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.797954</td>\n",
       "      <td>-0.556109</td>\n",
       "      <td>-0.637167</td>\n",
       "      <td>0.147260</td>\n",
       "      <td>0.217914</td>\n",
       "      <td>2.718442</td>\n",
       "      <td>0.972919</td>\n",
       "      <td>2.081069</td>\n",
       "      <td>1.375763</td>\n",
       "      <td>1.063847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.805626</td>\n",
       "      <td>0.166616</td>\n",
       "      <td>-0.178325</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>-0.724247</td>\n",
       "      <td>-1.020687</td>\n",
       "      <td>-0.751380</td>\n",
       "      <td>-0.385005</td>\n",
       "      <td>-0.012326</td>\n",
       "      <td>-0.392197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180181</td>\n",
       "      <td>-0.500785</td>\n",
       "      <td>-0.919463</td>\n",
       "      <td>-0.667912</td>\n",
       "      <td>-0.820172</td>\n",
       "      <td>-0.190488</td>\n",
       "      <td>0.306974</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.271838</td>\n",
       "      <td>1.289783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1  0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2 -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3 -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4  0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "\n",
       "         7         8         9   ...        58        59        60        61  \\\n",
       "0 -1.205671  1.849122 -0.425598  ... -0.944584 -0.043610 -1.504263  0.351267   \n",
       "1 -0.887385  0.432062 -0.093963  ... -0.082645 -0.947933 -0.495712 -0.465077   \n",
       "2 -0.694895 -0.901869 -1.701574  ... -0.797954 -0.556109 -0.637167  0.147260   \n",
       "3  0.114752  0.692847  0.052377  ... -0.805626  0.166616 -0.178325 -0.065059   \n",
       "4 -0.401676 -0.872639  1.147483  ... -0.180181 -0.500785 -0.919463 -0.667912   \n",
       "\n",
       "         62        63        64        65        66        67  \n",
       "0 -1.018726 -0.174878 -1.089543 -0.668840 -0.914772 -0.836250  \n",
       "1 -0.157861 -0.157189  0.380951  1.088478 -0.123595  1.391141  \n",
       "2  0.217914  2.718442  0.972919  2.081069  1.375763  1.063847  \n",
       "3 -0.724247 -1.020687 -0.751380 -0.385005 -0.012326 -0.392197  \n",
       "4 -0.820172 -0.190488  0.306974  0.119658  0.271838  1.289783  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features set 'X', and the target 'y' set\n",
    "\n",
    "# The features dataset consists of columns 0 to 67\n",
    "X = df.iloc[:, 0:68]\n",
    "\n",
    "# The target conststs of columns 68 and 69\n",
    "y = df.iloc[:, 68:70]\n",
    "\n",
    "# View data for the features set\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Split the data into training and test sets using the `train_test_split` method from `sklearn`. Then scale the features data using an instance of the `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into traning and testing sets using the train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data for the features set X_tain and X_test\n",
    "\n",
    "# Fit the training data to a StandardScaler instance\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Scale the training data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# Scale the testing data\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Using the training set, construct a shallow neural net model to predict the credit score data (you can use the same model that you constructed in the _Credit Scoring_ Activity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shallow, 1 hidden layer, neural network\n",
    "\n",
    "# Instantiate an instance of the Sequential model\n",
    "nn = Sequential()\n",
    "\n",
    "# Create 1 hidden layer\n",
    "nn.add(Dense(units=8, input_dim=68, activation='relu'))\n",
    "\n",
    "# Create the output layer\n",
    "nn.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and mse.\n",
    "nn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2469.4324 - mse: 2469.4324\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2438.4272 - mse: 2438.4272\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2403.0222 - mse: 2403.0222\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2361.4363 - mse: 2361.4363\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2313.5820 - mse: 2313.5820\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2260.0283 - mse: 2260.0283\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2201.8472 - mse: 2201.8472\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2140.2976 - mse: 2140.2976\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2075.7688 - mse: 2075.7688\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2010.9836 - mse: 2010.9836\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1947.6273 - mse: 1947.6273\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1885.3627 - mse: 1885.3627\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1827.2690 - mse: 1827.2690\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1773.4967 - mse: 1773.4967\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1724.0903 - mse: 1724.0903\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1679.9833 - mse: 1679.9833\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1641.6429 - mse: 1641.6429\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1607.7592 - mse: 1607.7592\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1577.4573 - mse: 1577.4573\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1552.0132 - mse: 1552.0132\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1529.8702 - mse: 1529.8702\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1511.2322 - mse: 1511.2322\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1494.3635 - mse: 1494.3635\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1479.9962 - mse: 1479.9962\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1467.4993 - mse: 1467.4993\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1455.5347 - mse: 1455.5347\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1445.8605 - mse: 1445.8605\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1435.8505 - mse: 1435.8505\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1427.3228 - mse: 1427.3228\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1419.4103 - mse: 1419.4103\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1411.7583 - mse: 1411.7583\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1404.8729 - mse: 1404.8729\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1397.5619 - mse: 1397.5619\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1391.5441 - mse: 1391.5441\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1385.0054 - mse: 1385.0054\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1379.0398 - mse: 1379.0398\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1373.0513 - mse: 1373.0513\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1367.1880 - mse: 1367.1880\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1361.4225 - mse: 1361.4225\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1355.9806 - mse: 1355.9806\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1350.6572 - mse: 1350.6572\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1345.5322 - mse: 1345.5322\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1340.4408 - mse: 1340.4408\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1335.4862 - mse: 1335.4862\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1330.8009 - mse: 1330.8009\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1325.8782 - mse: 1325.8782\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1321.4761 - mse: 1321.4761\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1317.0050 - mse: 1317.0050\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1312.4279 - mse: 1312.4279\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1307.9928 - mse: 1307.9928\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1303.8501 - mse: 1303.8501\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1299.5037 - mse: 1299.5037\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1295.6836 - mse: 1295.6836\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1292.0848 - mse: 1292.0848\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1288.3221 - mse: 1288.3221\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1284.9099 - mse: 1284.9099\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1281.2950 - mse: 1281.2950\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1278.0007 - mse: 1278.0007\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1274.4955 - mse: 1274.4955\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1271.1570 - mse: 1271.1570\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1267.7427 - mse: 1267.7427\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1264.6128 - mse: 1264.6128\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1261.6295 - mse: 1261.6295\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1258.4401 - mse: 1258.4401\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1255.6459 - mse: 1255.6459\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1253.2427 - mse: 1253.2427\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1250.2292 - mse: 1250.2292\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1247.1232 - mse: 1247.1232\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1244.5784 - mse: 1244.5784\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1241.8746 - mse: 1241.8746\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1239.5918 - mse: 1239.5918\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1236.6880 - mse: 1236.6880\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1234.1343 - mse: 1234.1343\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1231.7615 - mse: 1231.7615\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1229.2820 - mse: 1229.2820\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1227.5928 - mse: 1227.5928\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1224.9954 - mse: 1224.9954\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1222.2964 - mse: 1222.2964\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1220.1038 - mse: 1220.1038\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1217.8356 - mse: 1217.8356\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1215.5656 - mse: 1215.5656\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1213.2982 - mse: 1213.2982\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1211.1151 - mse: 1211.1151\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1208.9684 - mse: 1208.9684\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1206.7921 - mse: 1206.7921\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1204.8792 - mse: 1204.8792\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1203.1484 - mse: 1203.1484\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1200.7872 - mse: 1200.7872\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1199.0271 - mse: 1199.0271\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1196.9854 - mse: 1196.9854\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1195.0542 - mse: 1195.0542\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1193.3250 - mse: 1193.3250\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1191.7849 - mse: 1191.7849\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1190.0148 - mse: 1190.0148\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1188.0901 - mse: 1188.0901\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1186.4580 - mse: 1186.4580\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1184.9930 - mse: 1184.9930\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1183.1541 - mse: 1183.1541\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1181.2665 - mse: 1181.2665\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1179.7463 - mse: 1179.7463\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using the training data\n",
    "model_1 = nn.fit(X_train_scaled, y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAskElEQVR4nO3deXxV9Z3/8dcnC9kXyE4SCMgii6ISEKui4gJ2VOxop7TWbfzV3zjWaqd1Oozz6zKdTmdqt9/U6ow/tcqMa9XWpYprLVoRBGRfwx4CZIFAQiCQ5PP74x4wxmAWEm5y7/v5eNxHbr7n3Hs/X5b3Oef7Pfccc3dERCQ6xIS7ABEROXkU+iIiUUShLyISRRT6IiJRRKEvIhJFFPoiIlFEoS+dZmZbzOySk/yZZma/MbO9ZrbwJH/2q2Z248n8zJ5iZkPMrN7MYntyXen/4sJdgEgHzgMuBYrc/UBvfYiZfR8Y4e5fPdrm7pf31ud1UMtNwP9y9/O6+x7uvg1I7el1pf/Tnr70dUOBLb0Z+P2R9sqluxT60i1mlmBmvzSziuDxSzNLCJZlm9nLZlZrZnvM7F0ziwmWfcfMdphZnZmtM7OLP+MzbgEeAs4Jhh9+YGY3mdl7bdZzMxsRPH/UzH5tZn8IPmOBmZ3Sat1xZvZGUNduM/tHM5sB/CPwpeBzlgXrvmNm/yt4HmNm/2RmW82s0szmmFlGsKwkqOFGM9tmZtVmdk83/1zHAP/Zqs+1rfr1gJm9YmYHgIvM7C/M7CMz229m24OjlaPvc7SmuFZ9+aGZ/Tn4c3ndzLK7um6w/Ibgz6HGzP5POIb9pPsU+tJd9wBTgDOACcBk4J+CZd8CyoEcII9QoLqZjQa+Dkxy9zRgOrDleB/g7g8DfwPMd/dUd/9eJ2v7MvADYCBQBvwIwMzSgDeBucBgYATwlrvPBf4VeDr4nAntvOdNweMiYDih4ZD72qxzHjAauBj4bhDgXeLua/hknzNbLf5K0Jc04D3gAHADkAn8BXCbmV39GW//FeBmIBcYAHy7q+ua2VjgfuA6oADIAAq70EUJM4W+dNd1wD+7e6W7VxEK2euDZUcIBcJQdz/i7u966CJPzUACMNbM4t19i7tv7IXannf3he7eBDxOaMMEcAWwy91/5u6H3L3O3Rd08j2vA37u7pvcvR6YDcw6uncc+IG7H3T3ZcAyQhvDnvSCu//Z3VuC+t9x9xXB78uBJ4ELPuP1v3H39e5+EHiGj/9curLutcBL7v6eux8GvgvoAl79iEJfumswsLXV71uDNoB7Ce1hv25mm8zsHwDcvQy4C/g+UGlmT5nZYHrerlbPG/h4krIY6O5Gpr3+xhE6kunoc49pdaZMvZnVd7GG7W3e62wz+6OZVZnZPkJHCNntv7Rz9XVi3cGt63D3BqCmE7VLH6HQl+6qIDTJetSQoI1gD/pb7j4cuBL4u6Nj9+7+RHBWylBCe4j/3sXPPQAkH/3FzPK78NrtwCnHWdbR3mp7/W0Cdnfh83H3bcGwTaq7Hy90j1dL2/YngBeBYnfPIDQXYF2ppxt2AkVHfzGzJCCrlz9TepBCX7rrSeCfzCwnmOT7LvA/AGZ2hZmNMDMD9hMa1mk2s9FmNi2Y8D0EHAyWdcUyYJyZnWFmiYSOGjrrZSDfzO4KJqLTzOzsYNluoOTohPNx+vtNMxtmZql8PAfQ1MX6O2M3UGRmAzpYLw3Y4+6HzGwyoXH43vYscKWZfS6o7wf0/oZGepBCX7rrX4BFwHJgBbAkaAMYSWjCtB6YD9zv7u8QGs//N6Ca0PBBLqFJ3k5z9/XAPwfvv4HQhGZnX1tH6Jz/K4PP30BoYhbgt8HPGjNb0s7LHwH+G5gHbCa00bqjK7V3wdvAKmCXmVV/xnp/C/yzmdUR2ug+00v1HOPuqwj1+ylCe/11QCXQ2NufLT3DdBMVEemu4KinFhjp7pvDXI50gvb0RaRLzOxKM0s2sxTgp4SO9LaEtyrpLIW+hJ2FrnFT386jS0M/ctLMJDSxXUFoKG+Wa8ig39DwjohIFNGevohIFOnzV9nMzs72kpKScJchItKvLF68uNrdc9q29/nQLykpYdGiReEuQ0SkXzGzre21a3hHRCSKKPRFRKKIQl9EJIr0+TF9EZETdeTIEcrLyzl06FC4S+lxiYmJFBUVER8f36n1FfoiEvHKy8tJS0ujpKSE0HUAI4O7U1NTQ3l5OcOGDevUazS8IyIR79ChQ2RlZUVU4AOYGVlZWV06glHoi0hUiLTAP6qr/YrI0Hd3nvlwO6+v2tXxyiIiUSQix/SbW5z//mArO/cdZPKwQWQmd3QvChGR3pWamkp9fVfvkNnzInJPPy42hn+/5nRqG47wL39YE+5yRET6jIgMfYCxg9P5mwtO4dnF5cxbXxXuckREgNDw891338348eM57bTTePrppwHYuXMnU6dO5YwzzmD8+PG8++67NDc3c9NNNx1b9xe/+MUJf35EDu8c9fVpI3h15U5mP7+C1785lZSEiO6uiHTCD15axeqK/T36nmMHp/O9K8d1at3nn3+epUuXsmzZMqqrq5k0aRJTp07liSeeYPr06dxzzz00NzfT0NDA0qVL2bFjBytXrgSgtrb2hGuN2D19gMT4WP79mtOp2HeQn72+PtzliIjw3nvv8eUvf5nY2Fjy8vK44IIL+PDDD5k0aRK/+c1v+P73v8+KFStIS0tj+PDhbNq0iTvuuIO5c+eSnp5+wp8f8bu+pSWD+MrkITw2fwtfObuYEblp4S5JRMKos3vkveV4N66aOnUq8+bN4w9/+APXX389d999NzfccAPLli3jtdde49e//jXPPPMMjzzyyAl9fkTv6R/1d5eOInlALD/SpK6IhNnUqVN5+umnaW5upqqqinnz5jF58mS2bt1Kbm4uX/va17jllltYsmQJ1dXVtLS0cM011/DDH/6QJUuWnPDnR/yePkBWagJ3TBvBv76ylnnrq5g66lP3FRAROSm+8IUvMH/+fCZMmICZ8ZOf/IT8/Hwee+wx7r33XuLj40lNTWXOnDns2LGDm2++mZaWFgB+/OMfn/Dnd3iPXDMrBuYA+UAL8KC7/99Wy78N3AvkuHt10DYbuAVoBr7h7q8F7ROBR4Ek4BXgzo5uqFxaWuo9cROVxqZmLvvFPBLiYnjlG+cTFxsVBzkiAqxZs4YxY8aEu4xe017/zGyxu5e2XbczydcEfMvdxwBTgNvNbGzwpsXApcC2Vh80FpgFjANmAPebWWyw+AHgVmBk8JjRta51X0JcLLMvP5X1u+t56sPtJ+tjRUT6lA5D3913uvuS4HkdsAYoDBb/Avh7oPXe+kzgKXdvdPfNQBkw2cwKgHR3nx/s3c8Bru6xnnTC9HH5TB42iF++uYFDR5pP5keLiPQJXRrjMLMS4ExggZldBexw92VtVisEWu9KlwdthcHztu3tfc6tZrbIzBZVVfXcF6vMjG9eMorq+kaeWaS9fZFo0tFQdn/V1X51OvTNLBV4DriL0JDPPcB321u1vbo+o/3Tje4Punupu5fm5PTspOuU4YMoHTqQ//rTJg43tfToe4tI35SYmEhNTU3EBf/R6+knJiZ2+jWdOnvHzOIJBf7j7v68mZ0GDAOWBZf1LAKWmNlkQnvwxa1eXgRUBO1F7bSfVGbG7dNGcPNvPuT3H+3gryYVd/wiEenXioqKKC8vpydHDvqKo3fO6qwOQ99Cqf4wsMbdfw7g7iuA3FbrbAFK3b3azF4EnjCznwODCU3YLnT3ZjOrM7MpwALgBuBXna60B104Kofxhenc/04Z10wsIjYmMq+zLSIh8fHxnb6zVKTrzPDOucD1wDQzWxo8Pn+8ld19FfAMsBqYC9zu7kdnTW8DHiI0ubsRePVEiu8uM+PrF41gS00DLy8/6QcbIiJh0+F5+uHWU+fpt9XS4kz/5TxiY4xX7zw/Yu+qIyLR6UTO049IMTHG16YOZ+2uOhZs3hPuckREToqoDX2AqyYMJjM5njnzt4S7FBGRkyKqQz8xPpa/Ki3mtVW72bWv83eTFxHpr6I69AG+evZQWtx5YsHWcJciItLroj70h2Qlc9HoXJ5YuF1f1hKRiBf1oQ9w/TlDqa5vZO6qXeEuRUSkVyn0gQtG5jA0K5k5728JdykiIr1KoU/o9M3rzh7Coq17KausD3c5IiK9RqEfuPrMQmJjjOeWlHe8sohIP6XQD+SmJXLhqByeX1JOc0vf/payiEh3KfRbuXZiEbv3N/JeWXW4SxER6RUK/VamjcklMzmeZxdriEdEIpNCv5WEuFhmThjMa6t2se/gkXCXIyLS4xT6bVw7sZjDTS265LKIRCSFfhvjC9MZnZfGcxriEZEIpNBvw8y4ZmIhS7bVsqX6QLjLERHpUQr9dlxx+mAADfGISMRR6LdjcGYSk0sG8eIyhb6IRBaF/nFcOaGA9bvrWberLtyliIj0GIX+cVx+WgExBi9pb19EIohC/ziyUxM4d0Q2Ly2voK/fPF5EpLM6DH0zKzazP5rZGjNbZWZ3Bu33mtlaM1tuZr8zs8xWr5ltZmVmts7Mprdqn2hmK4Jl/2Fm1iu96iFXnj6YrTUNrNixL9yliIj0iM7s6TcB33L3McAU4HYzGwu8AYx399OB9cBsgGDZLGAcMAO438xig/d6ALgVGBk8ZvRgX3rc9HH5xMcaLy7VEI+IRIYOQ9/dd7r7kuB5HbAGKHT31929KVjtA6AoeD4TeMrdG919M1AGTDazAiDd3ed7aLxkDnB1z3anZ2Ukx3PBqFxeXr6TFl15U0QiQJfG9M2sBDgTWNBm0V8DrwbPC4HtrZaVB22FwfO27X3alRMK2LX/EEu27Q13KSIiJ6zToW9mqcBzwF3uvr9V+z2EhoAeP9rUzsv9M9rb+6xbzWyRmS2qqqrqbIm9YtqpuQyIjeHVlbp/roj0f50KfTOLJxT4j7v7863abwSuAK7zj09xKQeKW728CKgI2ovaaf8Ud3/Q3UvdvTQnJ6ezfekVaYnxnD8ym7krd+ksHhHp9zpz9o4BDwNr3P3nrdpnAN8BrnL3hlYveRGYZWYJZjaM0ITtQnffCdSZ2ZTgPW8AXujBvvSay08rYEftQZaX6yweEenfOrOnfy5wPTDNzJYGj88D9wFpwBtB238CuPsq4BlgNTAXuN3dm4P3ug14iNDk7kY+ngfo0y4dk0dcjPHKyp3hLkVE5IRYXx+yKC0t9UWLFoW7DG54ZCFbaw7wzrcvpI9/vUBEBDNb7O6lbdv1jdxOunx8PltrGlizU9fiEZH+S6HfSZeNzSPG4FUN8YhIP6bQ76Ss1ATOHpalUzdFpF9T6HfB5aflU1ZZz4bdGuIRkf5Jod8Fl43NB+D11bvDXImISPco9LsgPyORCUUZCn0R6bcU+l102bh8lm2vZff+Q+EuRUSkyxT6XXTp2DwA3tDevoj0Qwr9LhqZm0pJVrKGeESkX1Lod5GZcdm4fOZvrKbu0JFwlyMi0iUK/W64dGweR5qdd9aF97LPIiJdpdDvhrOGDCQrZYCGeESk31Hod0NsjHHxmFzeWVvJ4aaWcJcjItJpCv1uumxsPnWNTXywqSbcpYiIdJpCv5vOG5lNUnysTt0UkX5Fod9NifGxnD8ymzdW79ZtFEWk31Don4DLxuWza/8hVuzQbRRFpH9Q6J+AaafmEmP6dq6I9B8K/RMwKGUApSWDFPoi0m8o9E/QZWPzWLurjm01DeEuRUSkQwr9E/TxNfZ1Ry0R6fsU+idoSFYyo/PSNMQjIv1Ch6FvZsVm9kczW2Nmq8zszqB9kJm9YWYbgp8DW71mtpmVmdk6M5veqn2ima0Ilv2HmVnvdOvkunRsHh9u2cOeA4fDXYqIyGfqzJ5+E/Atdx8DTAFuN7OxwD8Ab7n7SOCt4HeCZbOAccAM4H4ziw3e6wHgVmBk8JjRg30Jm8vG5dHi8NYa7e2LSN/WYei7+053XxI8rwPWAIXATOCxYLXHgKuD5zOBp9y90d03A2XAZDMrANLdfb6Hvs00p9Vr+rXTCjMoyEjUBdhEpM/r0pi+mZUAZwILgDx33wmhDQOQG6xWCGxv9bLyoK0weN62vb3PudXMFpnZoqqqvn/5YjPjsrF5zFtfRcPhpnCXIyJyXJ0OfTNLBZ4D7nL3/Z+1ajtt/hntn250f9DdS929NCcnp7MlhtX0cfk0NrUwb33f30iJSPTqVOibWTyhwH/c3Z8PmncHQzYEPyuD9nKguNXLi4CKoL2onfaIMHnYIDKT43ltlYZ4RKTv6szZOwY8DKxx95+3WvQicGPw/EbghVbts8wswcyGEZqwXRgMAdWZ2ZTgPW9o9Zp+Ly42hkvG5PHWmt0cadY19kWkb+rMnv65wPXANDNbGjw+D/wbcKmZbQAuDX7H3VcBzwCrgbnA7e7eHLzXbcBDhCZ3NwKv9mRnwm36uHz2H9I19kWk74rraAV3f4/2x+MBLj7Oa34E/Kid9kXA+K4U2J+cPzKb5AGxvLZqF+eP7B9zESISXfSN3B6UGB/LBaNyeH3VblpadI19Eel7FPo9bPq4fCrrGllaXhvuUkREPkWh38MuOjWX+FjjtZW6AJuI9D0K/R6WkRTP507JZu6qXbqNooj0OQr9XjBjfD5baxpYs7Mu3KWIiHyCQr8XXDo2jxiDuas0xCMifYtCvxdkpyYwqWQQc1fuDHcpIiKfoNDvJTPG57N+dz0bq+rDXYqIyDEK/V4yfVzoNopzdRaPiPQhCv1eMjgziQnFmbymcX0R6UMU+r1oxrh8lpfvo3xvQ7hLEREBFPq9asZ4DfGISN+i0O9Fw7JTGFuQzkvLdRaPiPQNCv1edtUZg1m2vZZtNRriEZHwU+j3sitOLwDgpeURc5MwEenHFPq9rGhgMhOHDuSlZQp9EQk/hf5JcOXpBazdVcf63boWj4iEl0L/JPj86QXEGLysvX0RCTOF/kmQm5bIOadk8eKyCl1uWUTCSqF/klx5+mC21DSwcsf+cJciIlFMoX+SXD6+gPhY44WlO8JdiohEMYX+SZKRHM9Fo3P5/dIKmppbwl2OiESpDkPfzB4xs0ozW9mq7Qwz+8DMlprZIjOb3GrZbDMrM7N1Zja9VftEM1sRLPsPM7Oe707fdu3EIqrrG5m3oSrcpYhIlOrMnv6jwIw2bT8BfuDuZwDfDX7HzMYCs4BxwWvuN7PY4DUPALcCI4NH2/eMeBeOzmVQygCeXVwe7lJEJEp1GPruPg/Y07YZSA+eZwBHz0WcCTzl7o3uvhkoAyabWQGQ7u7zPXT6yhzg6h6ov18ZEBfDzDMG8+bqSmobDoe7HBGJQt0d078LuNfMtgM/BWYH7YXA9lbrlQdthcHztu3tMrNbg2GjRVVVkTUUcs1ZRRxubtE3dEUkLLob+rcB33T3YuCbwMNBe3vj9P4Z7e1y9wfdvdTdS3NycrpZYt80bnA6p+an8ewSncUjIidfd0P/RuD54PlvgaMTueVAcav1iggN/ZQHz9u2Rx0z49qJRSzbXktZpS7LICInV3dDvwK4IHg+DdgQPH8RmGVmCWY2jNCE7UJ33wnUmdmU4KydG4AXTqDufm3mGYXExhi/1YSuiJxknTll80lgPjDazMrN7Bbga8DPzGwZ8K+EzsrB3VcBzwCrgbnA7e7eHLzVbcBDhCZ3NwKv9nBf+o2ctASmnZrLs4vKOdykc/ZF5OSJ62gFd//ycRZNPM76PwJ+1E77ImB8l6qLYNedPYQ3Vu/mtVW7uHLC4HCXIyJRQt/IDZOpI3MoGpjE4wu2hrsUEYkiCv0wiYkxvnL2ED7YtIeyyvpwlyMiUUKhH0ZfnFhMfKzx5MJt4S5FRKKEQj+MctISmD4un2cXl3PoSHPHLxAROUEK/TD7ytlD2HfwCH9YvjPcpYhIFFDoh9k5w7MYnpPCY/O36K5aItLrFPphZmb89bnDWF6+j4Wb217XTkSkZyn0+4BrJxYxKGUAD87bFO5SRCTCKfT7gMT4WG44Zyhvra3U9XhEpFcp9PuI66cMJSEuhv83b3O4SxGRCKbQ7yOyUhP4YmkRv/toB5V1h8JdjohEKIV+H3LLecM50tLCY+9vCXcpIhKhFPp9yLDsFGaMy2fO+1vZe0C3UxSRnqfQ72O+eeko6g838Z/zNoa7FBGJQAr9PmZUXhpfOKOQx97fwu79GtsXkZ6l0O+D7rpkFE3Nzn1vl4W7FBGJMAr9PmhIVjKzJhfz5MJtbKtpCHc5IhJBFPp91B3TRhIbY/zizfXhLkVEIohCv4/KS0/k5nOH8buPdvDRtr3hLkdEIoRCvw/7+rQR5KYl8L0XV9HSoitwisiJU+j3YakJcfzj58ewvHwfzyzaHu5yRCQCdBj6ZvaImVWa2co27XeY2TozW2VmP2nVPtvMyoJl01u1TzSzFcGy/zAz69muRKaZZwxmUslAfvLaOvY1HAl3OSLSz3VmT/9RYEbrBjO7CJgJnO7u44CfBu1jgVnAuOA195tZbPCyB4BbgZHB4xPvKe0zM75/1ThqGw7zszfWhbscEennOgx9d58HtL27x23Av7l7Y7BOZdA+E3jK3RvdfTNQBkw2swIg3d3ne+j2UHOAq3uoDxFv3OAMvjplKP/zwVaWaFJXRE5Ad8f0RwHnm9kCM/uTmU0K2guB1oPP5UFbYfC8bbt00t3TR5Ofnsjdv12mm6iLSLd1N/TjgIHAFOBu4JlgjL69cXr/jPZ2mdmtZrbIzBZVVVV1s8TIkpYYz4+vOZ2NVQf45Zsbwl2OiPRT3Q39cuB5D1kItADZQXtxq/WKgIqgvaid9na5+4PuXurupTk5Od0sMfJcMCqHL5UW8+C8jSzbXhvuckSkH+pu6P8emAZgZqOAAUA18CIwy8wSzGwYoQnbhe6+E6gzsynBEcENwAsnWnw0uueKMeSmJfLt3y7j4GEN84hI13TmlM0ngfnAaDMrN7NbgEeA4cFpnE8BNwZ7/auAZ4DVwFzgdnc/mky3AQ8RmtzdCLza472JAumJ8fzk2tMpq6pn9vPLCc2Li4h0jvX10CgtLfVFixaFu4w+51dvbeBnb6zn+1eO5aZzh4W7HBHpY8xssbuXtm3XN3L7qdsvGsElY3L5lz+sYeHmtmfUioi0T6HfT8XEGD//0hkUD0rmbx9fwvY9ugSziHRMod+PpSfG8+D1Eznc1MyNjyxkj+6rKyIdUOj3cyPz0nj4pknsqD3IzY9+yIHGpnCXJCJ9mEI/AkwqGcR9XzmLFeW13Pb4EhqbdCqniLRPoR8hLh2bx4//8jTmra/ilkcXaY9fRNql0I8gX5o0hJ9+cQLzN9Vw3UMLqG3QGL+IfJJCP8JcO7GI+687i9UV+/mr/5pPRe3BcJckIn2IQj8CTR+Xz6M3T2Jn7SFm/vrPLNV1ekQkoNCPUJ8bkc1zf/s5EuJi+NJ/zeelZce9vp2IRBGFfgQblZfGC7efy2mFGdzx5Ef88OXVOrNHJMop9CNcVmoCj3/tbK6fMpSH39vM1b9+n7LKunCXJSJhotCPAglxsfzw6vE8dEMpu/cf4opfvcdD726iqbkl3KWJyEmm0I8il4zNY+6d53PuKdn8yx/WcNV9muQViTYK/SiTm57IQzeW8sB1Z1FzoJEv3P9n7vndCp3TLxIlFPpRyMy4/LQC3vy7C7jpcyU89eF2LvrpOzy5cBstLX37/goicmIU+lEsLTGe7105jpfvOI+RuWnMfn4F0385j99/tEPj/SIRSqEvjClI5+n/PYX7vnImMWbc9fRSpv3sTzz94TaOKPxFIopulyif0NLivLlmN/f9sYzl5fsoGpjE1y8awV+eVcSAOO0jiPQXx7tdokJf2uXuvLOuil++uZ5l5fvIS0/gurOH8uXJQ8hJSwh3eSLSAYW+dIu786f1VTz83mbe3VDNgNgYPn9aPrMmD+HsYYMws3CXKCLtOF7ox4WjGOk/zIwLR+dy4ehcNlbVM+f9LTz/0Q5+v7SCYdkpfGlSMX95ZiG56YnhLlVEOqHDPX0zewS4Aqh09/Ftln0buBfIcffqoG02cAvQDHzD3V8L2icCjwJJwCvAnd6Jwwzt6fc9Bw8388qKnTz14TY+3LKX2BjjwlE5XDuxiItOzSUxPjbcJYpEvRPZ038UuA+Y0+YNi4FLgW2t2sYCs4BxwGDgTTMb5e7NwAPArcAHhEJ/BvBqdzoj4ZU0IJZrJhZxzcQiNlbV8+zicp5bXM5baytJTYjjsrF5XDlhMOePzCYuVpO/In1Jh6Hv7vPMrKSdRb8A/h54oVXbTOApd28ENptZGTDZzLYA6e4+H8DM5gBXo9Dv907JSeU7M07lW5eOYv6mGl5aVsHclbt4/qMdZKcO4KoJhVx95mBOK8zQ+L9IH9CtMX0zuwrY4e7L2vxHLiS0J39UedB2JHjetv14738roaMChgwZ0p0S5SSLi43h/JE5nD8yhx9ePZ4/ravidx/t4H8+2Mojf95Mfnoi08bkcsmYXM4dkU1CnIaARMKhy6FvZsnAPcBl7S1up80/o71d7v4g8CCExvS7WqOEV0JcLJeNy+eycfnsazjC66t38fbaSl74aAdPLNhGWkIc08bkcvn4fM4fmUNKgs4nEDlZuvO/7RRgGHB0L78IWGJmkwntwRe3WrcIqAjai9pplwiXkRzPF0uL+WJpMY1Nzby/sYa5K3bx+updvLC0ggGxMUw5JYuLT83l4jG5FA1MDnfJIhGtU+fpB2P6L7c9eydYtgUodfdqMxsHPAFMJjSR+xYw0t2bzexD4A5gAaGJ3F+5+ysdfbbO3olMTc0tLNyyh7fXVPL22ko2VR8AYHReGhePyWXaqbmcUZypiWCRbur2l7PM7EngQiAb2A18z90fbrV8C0HoB7/fA/w10ATc5e6vBu2lfHzK5qvAHTplU47aVFXP22sreWtNJQu37KG5xclMjmfqyBwuOjWHqSNzyErVN4FFOkvfyJV+Y9/BI7y3oZq311byp/WVVNcfxgxOL8rkglE5nD8ymzOKM4nXUYDIcSn0pV9qaXFWVuzjj2ur+OO6SpaX19LikJoQx5ThWZw3IovzRmZzSk6qTgkVaUWhLxFhX8MR3t9Yzbtl1fy5rJqtNQ0A5KYlcM4pWZwzPItzTsliyKBkbQQkqin0JSJt39PAn8uqeX9jDe9vrKG6vhGAwRmJTAk2AlOGZ1E0MEkbAYkqCn2JeO5OWWU98zfVMH9jDR9sqmFvwxEgtBE4e3gWpSUDmVQyiBE5qcTEaCMgkUuhL1GnpcXZUFnPgs01LNi0h4Vb9lBVFzoSyEiKZ1LJIKYMH8TkYYMYU5CuiWGJKLq0skSdmBhjdH4ao/PTuOGcEtydbXsa+HDLXhZurmHB5j28uWY3AAlxMZxelMGZQwZy1pBMzhoyUJeLloikPX2Jarv2HeLDLXv4aFstH23fy6od+zkc3Be4aGASE4cOZOLQgZw1ZCCn5qfpy2LSb2h4R6QTGpuaWVWxnyVb97Jk214Wb93L7v2hIaHkAbGcXpTBWUMGcnpRJhOKM8hPT9QEsfRJGt4R6YSEuFjOGhLas4fQ5HD53oMs2baXj7bVsmTbXh6ct4mmltDOUk5aAhOKMjlzSCZnFmcyrjCDjKT4cHZB5DMp9EU+g5lRPCiZ4kHJzDwjdDXwQ0eaWb1zP8u317KsfB/LttcemxsAKB6UxLiCDMYOTufU/DTGFKRTmJmks4WkT1Doi3RRYvwnjwYAahsOs3R7Lasq9rO6Yj+rKvbx2updHB09TUuI49SCNMYWpHNqQTqj8tIYlZdKWqKOCuTkUuiL9IDM5AHHbiB/1IHGJtbvrmPNzjrW7NzPmp37eXZxOQcONx9bpzAz6djRwKj80IZgWHaKbjIjvUahL9JLUhLiOHPIQM5sdUTQ0uLsqD3Iul11rNtdx/rddazdWcef1lcdmyeIMSjJSjl2uunovDRG5qVRkpWss4fkhCn0RU6imJiP5wguGZt3rL2xqZlNVQfYUFlP2e7QBmHtrjrmrvp4iCg+1hienRo6IshNZWReGiNyUxmalawvlkmnKfRF+oCEuFjGFKQzpiD9E+0HDzdTVlnPhso61u+uZ8PuOpZu38tLyz6+8VxcjDFkUDLDc1IYlp3CsOxUTslJYURuqu5BIJ+i0Bfpw5IGxHJaUQanFWV8ov1AYxNllfVsqq5nY+UBNlbVs7n6AO9uqKaxqeXYegOT4xmalUJJVjJDslIoGphEUWYSgzOTKByYpCOEKKTQF+mHUhLimFCcyYTizE+0t7Q4FfsOsrHqAGWV9ZRV1rO15gAfbtnLC8sqaP1dzKNHCMOyUzglN5Xhwc+hWcnkpCboS2cRSqEvEkFiYoyigckUDUzmglE5n1jW2NTMrn2H2LH3IOW1B9lac4BNVaHHu2XVHG51hJAQF0PRwCSKByUzJHgUD0pmcEYSBZmJZKUM0Eahn1Loi0SJhLhYhmalMDQr5VPLmlucitqDlFXVs62mgfK9DWzfc5DtextYvGUvdY1Nn1g/MT6GkqwUSrJSGJqdTPHA0EahaGAShZlJJMbrlNO+SqEvIsS2OquoLXdnb8MRduw9SMW+g+ysPci2PQfZUnOA9bvreGvtbo40f/IaXlkpAxicmRSaQxgYmkPITk0gK2UA2WkJFGYmkZKg+AkH/amLyGcyMwalDGBQyoBPTShD6Cihsu4Q2/ccpHxvAzv3HaJ870F21B5k/e463l5b+YnJ5aMGpQxoNXyUxJBByQzOTKIgI5H8jCRStVHoFfpTFZETEhtjFGQkUZCRxORhgz613N3Zc+AwNQcOU1N/mKr6xmPDR+V7G1i2vZZXVuykueWTRwtpCXEUZCZSkJHE4OBnQUbisQ1DQUYSSQM0jNRVHYa+mT0CXAFUuvv4oO1e4ErgMLARuNnda4Nls4FbgGbgG+7+WtA+EXgUSAJeAe70vn5dZxE5YWZGVmpC6DsDee2v09TcQkXtIXbuO8iu/YeoqD3Ern0HqdgXalu5Yx81Bw5/6nUDk+PJDzYGeemJ5Kcnhp5nJAZHDImkJcRp0rmVzuzpPwrcB8xp1fYGMNvdm8zs34HZwHfMbCwwCxgHDAbeNLNR7t4MPADcCnxAKPRnAK/2VEdEpP+Ki41hSFYyQ7I+Padw1KEjobOPQvMKH28gdu0LbSSWba9td8OQPCCWnLQEclITyElLCM0tpA4gOzU0tzA4M3RGUrRsHDoMfXefZ2Ylbdpeb/XrB8C1wfOZwFPu3ghsNrMyYLKZbQHS3X0+gJnNAa5GoS8inZQYH0tJdgol2Z8+++ioxqZmKvc3snPfIXbtP8Tu4GdlXSNVdYdYt7uO+ZtqqG048qnXJsTFkJ2aQHbqAHLTE8lLTyA3LZHctARyg+dZqaG5jf58QbyeGNP/a+Dp4HkhoY3AUeVB25Hgedv2dpnZrYSOChgyZEgPlCgi0SAhLva4ZyG1dqS5her6RipqD1FRe5Cd+w4em2+orj/M9j0NLN66lz3tHDkApCXGMShlAAOTBxyb5D66wchJCx1R5AZHFemJ8X3qXgonFPpmdg/QBDx+tKmd1fwz2tvl7g8CD0LodoknUqOISFvxsTHHJp8nDh143PUam5qprj9MZXC0UFN/mJr6RmoOHGbPgcPsbTjMrn2HWF2xn5oDjZ86dRVCE92hjUM8mUkDyEyOZ1DKxxuHo8NOR4eekgfE9uowU7dD38xuJDTBe3GrCdlyoLjVakVARdBe1E67iEiflRAXS2Fm6AtnHXF39h9soqr+6HBS6Khhz4HG0AbiwBH2Nhxma00DS7bVsudAIy3t7NIOiI05tmF47rbP9fj3Gbr1bmY2A/gOcIG7N7Ra9CLwhJn9nNBE7khgobs3m1mdmU0BFgA3AL86sdJFRPoOMyMjOZ6M5HhG5KZ1uH5zS+hU1tDGofHYz70NR9gbHEUk9cI3mztzyuaTwIVAtpmVA98jdLZOAvBGcBjygbv/jbuvMrNngNWEhn1uD87cAbiNj0/ZfBVN4opIFIuNsWPDOieT9fVT5UtLS33RokXhLkNEpF8xs8XuXtq2XRfTFhGJIgp9EZEootAXEYkiCn0RkSii0BcRiSIKfRGRKKLQFxGJIn3+PH0zqwK2dvPl2UB1D5bTH0RjnyE6+x2NfYbo7Hd3+jzU3XPaNvb50D8RZraovS8nRLJo7DNEZ7+jsc8Qnf3uyT5reEdEJIoo9EVEokikh/6D4S4gDKKxzxCd/Y7GPkN09rvH+hzRY/oiIvJJkb6nLyIirSj0RUSiSESGvpnNMLN1ZlZmZv8Q7np6i5kVm9kfzWyNma0yszuD9kFm9oaZbQh+Hv8moP2UmcWa2Udm9nLwezT0OdPMnjWztcHf+TmR3m8z+2bwb3ulmT1pZomR2Gcze8TMKs1sZau24/bTzGYH+bbOzKZ35bMiLvTNLBb4NXA5MBb4spmNDW9VvaYJ+Ja7jwGmALcHff0H4C13Hwm8Ffweae4E1rT6PRr6/H+Bue5+KjCBUP8jtt9mVgh8Ayh19/FALDCLyOzzo8CMNm3t9jP4Pz4LGBe85v4g9zol4kIfmAyUufsmdz8MPAXMDHNNvcLdd7r7kuB5HaEQKCTU38eC1R4Drg5Lgb3EzIqAvwAeatUc6X1OB6YCDwO4+2F3ryXC+03olq5JZhYHJAMVRGCf3X0esKdN8/H6ORN4yt0b3X0zUEYo9zolEkO/ENje6vfyoC2imVkJcCahG8/nuftOCG0YgNwwltYbfgn8PdDSqi3S+zwcqAJ+EwxrPWRmKURwv919B/BTYBuwE9jn7q8TwX1u43j9PKGMi8TQt3baIvq8VDNLBZ4D7nL3/eGupzeZ2RVApbsvDnctJ1kccBbwgLufCRwgMoY1jisYw54JDAMGAylm9tXwVtUnnFDGRWLolwPFrX4vInRIGJHMLJ5Q4D/u7s8HzbvNrCBYXgBUhqu+XnAucJWZbSE0dDfNzP6HyO4zhP5dl7v7guD3ZwltBCK535cAm929yt2PAM8DnyOy+9za8fp5QhkXiaH/ITDSzIaZ2QBCEx4vhrmmXmFmRmiMd427/7zVoheBG4PnNwIvnOzaeou7z3b3IncvIfR3+7a7f5UI7jOAu+8CtpvZ6KDpYmA1kd3vbcAUM0sO/q1fTGjeKpL73Nrx+vkiMMvMEsxsGDASWNjpd3X3iHsAnwfWAxuBe8JdTy/28zxCh3XLgaXB4/NAFqHZ/g3Bz0HhrrWX+n8h8HLwPOL7DJwBLAr+vn8PDIz0fgM/ANYCK4H/BhIisc/Ak4TmLY4Q2pO/5bP6CdwT5Ns64PKufJYuwyAiEkUicXhHRESOQ6EvIhJFFPoiIlFEoS8iEkUU+iIiUUShLyISRRT6IiJR5P8DyOpr0O6HLFwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the train function\n",
    "plt.plot(model_1.history[\"loss\"])\n",
    "plt.title(\"loss_function - training\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Using relative file paths, save the model and its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in JSON format\n",
    "nn_json = nn.to_json()\n",
    "\n",
    "# Define a relative path to save the model\n",
    "# The model should be saved with a .json file extension\n",
    "file_path = ('Resources/nn.json')\n",
    "\n",
    "# Write the model to the the file \n",
    "with open(file_path, 'w') as json_file:\n",
    "    json_file.write(nn_json)\n",
    "\n",
    "# Define a relative path to save the model weights\n",
    "# The model weights should be saved with a .h5 file extension\n",
    "file_path = ('Resources/nn.h5')\n",
    "\n",
    "# Save the weights to the file path\n",
    "nn.save_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load the model and its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model to predict values\n",
    "from tensorflow.keras.models import model_from_json\n",
    "# Identify the relative path of the model's location\n",
    "file_path = ('Resources/nn.json')\n",
    "\n",
    "# Read in the model and save it as the variable loaded_model\n",
    "with open('Resources/nn.json', 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "loaded_model= model_from_json(model_json)\n",
    "\n",
    "# Identify the relative path for the model's weights\n",
    "file_path = ('Resources/nn.h5')\n",
    "\n",
    "# Load the model's weights to the variable loaded_model\n",
    "loaded_model.load_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Use this loaded model to predict points for the test data and print the mean squared error metric for the predicted points vs. the actual points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.53068 ],\n",
       "       [44.4812  ],\n",
       "       [64.77518 ],\n",
       "       [20.324728],\n",
       "       [40.551758]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict values using the testing data\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# View the model's predictions\n",
    "y_pred[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (68!=2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10896\\3874043347.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Evaluate the model with the MSE metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \"\"\"\n\u001b[0;32m    438\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m     )\n\u001b[0;32m    441\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    105\u001b[0m         raise ValueError(\n\u001b[0;32m    106\u001b[0m             \"y_true and y_pred have different number of output ({0}!={1})\".format(\n\u001b[1;32m--> 107\u001b[1;33m                 \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             )\n\u001b[0;32m    109\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (68!=2)"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Evaluate the model with the MSE metric\n",
    "mse = mean_squared_error(X_test_scaled, y_test)\n",
    "print(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "nteract": {
   "version": "0.28.0"
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
